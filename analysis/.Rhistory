#Reference: https://github.com/dgrapov/TeachingDemos/wiki/Principal-Components-Analysis
if(normalisation_method %in% c("RLE","TMM","TMM50","median","upperquartile")){
counts<-t(as.matrix(abund_table))+1
cds<-NULL
if(normalisation_method=="RLE"){
cds<-calcNormFactors(DGEList(counts=counts,remove.zeros=TRUE),method="RLE")
} else if (normalisation_method=="TMM"){
cds<-calcNormFactors(DGEList(counts=counts,remove.zeros=TRUE),method="TMM")
} else if (normalisation_method=="TMM50"){
cds<-calcNormFactors(DGEList(counts=counts,remove.zeros=TRUE),method="TMM50",logratioTrim=0.49)
} else if (normalisation_method=="median"){
cds<-calcNormFactors(DGEList(counts=counts,remove.zeros=TRUE),method="upperquartile",p=0.5)
} else if (normalisation_method=="upperquartile"){
cds<-calcNormFactors(DGEList(counts=counts,remove.zeros=TRUE),method="upperquartile",p=0.75)
}
scale<-cds$samples$lib.size*cds$samples$norm.factors
normCounts <- round(t(t(counts)/scale)*mean(scale))
abund_table<-t(normCounts)
} else if(normalisation_method=="log-relative"){
abund_table<-log((abund_table+1)/(rowSums(abund_table)+dim(abund_table)[2]))
} else if(normalisation_method=="varstab"){
#From Susan Holme's paper
counts<-t(as.matrix(abund_table))+1
cds = newCountDataSet(counts, rep("A",dim(counts)[2]))
# First estimate library size factors
cds = estimateSizeFactors(cds)
# Variance estimation
cds = estimateDispersions(cds, method="blind", sharingMode="maximum", fitType="local")
# Determine which column(s) have the dispersion estimates
dispcol = grep("disp\\_", colnames(fData(cds)))
# Enforce that there are no infinite values in the dispersion estimates
if( any(!is.finite(fData(cds)[, dispcol])) ){
fData(cds)[which(!is.finite(fData(cds)[, dispcol])), dispcol] <- 0.0
}
vsmat = exprs(varianceStabilizingTransformation(cds))
abund_table<-t(vsmat)
} else if(normalisation_method=="CSS"){
#From mixOmics website
data.metagenomeSeq = newMRexperiment(t(abund_table),
featureData=NULL, libSize=NULL, normFactors=NULL) #using filtered data
p = cumNormStat(data.metagenomeSeq) #default is 0.5
data.cumnorm = cumNorm(data.metagenomeSeq, p=p)
#data.cumnorm
abund_table = t(MRcounts(data.cumnorm, norm=TRUE, log=TRUE))
} else if(normalisation_method %in% c("TSS+ILR","TSS+CLR")){
TSS.divide = function(x){
x/sum(x)
}
if(normalisation_method=="TSS+ILR"){
abund_table<-logratio.transfo(t(apply(abund_table+1, 1, TSS.divide)),logratio="ILR")
} else if (normalisation_method=="TSS+CLR"){
abund_table<-logratio.transfo(t(apply(abund_table+1, 1, TSS.divide)),logratio="CLR")
}
} else if(normalisation_method=="autoscaling"){
abund_table<-as.data.frame(scale(abund_table,center=T,scale=T))
} else if (normalisation_method=="naive-log2"){
abund_table<-log2(abund_table+1e-20)
} else if (normalisation_method=="arcsinh"){
#Apply arcsinh transformation (see Amir et al. 2013, Online Methods, "Processing of mass cytometry data")
Asinh_Scale <- 5
abund_table <- asinh(abund_table / Asinh_Scale)
} else if (normalisation_method=="mean-centering"){
#Reference:http://www.gastonsanchez.com/visually-enforced/how-to/2014/01/15/Center-data-in-R/
# center with 'colMeans()'
center_colmeans <- function(x) {
xcenter = colMeans(x)
x - rep(xcenter, rep.int(nrow(x), ncol(x)))
}
abund_table<-center_colmeans(abund_table)
} else if (normalisation_method=="paretoscaling"){
abund_table<-paretoscale(abund_table,exclude=T)
}
abund_table
}
#=============/Umer's fancy normalisation function ===============#
#PARAMETERS ###########################
#For DIABLO to work, we need combined "data", and a "design" matrix,
#you can put in as many abundance tables as you want, just make sure
#you choose an appripriate normalisation measure
normalisation_method_abund_table="TSS+CLR"
abund_table<-fancy_normalisation(abund_table,normalisation_method_abund_table)
mapping_table<-data.frame(row.names=colnames(abund_table),names=paste0("G",seq(1:ncol(abund_table))))
colnames(abund_table)<-mapping_table[colnames(abund_table),"names"]
View(abund_df)
normalisation_method_abund_table="TSS+CLR"
abund_table<-fancy_normalisation(abund_table,normalisation_method_abund_table)
abund_table<-fancy_normalisation(abund_table,normalisation_method_abund_table)
mapping_table<-data.frame(row.names=colnames(abund_table),names=paste0("G",seq(1:ncol(abund_table))))
colnames(abund_table)<-mapping_table[colnames(abund_table),"names"]
#ACHTUNG: From the RStudio menu, click on "Session" and then "Set Working Directory" to "To Source File Location"
#Script for Data Integration Analysis for Biomarker Discovery using latent variable approaches for 'Omic studies (DIABLO)
library(vegan)
library(ggplot2)
library(ape)
library(phangorn)
library(stringr)
library(reshape2)
library(mixOmics)
#PARAMETERS ###########################
abund_table<-read.csv("../generate_abundance_weighted_tables/abund_table_COMP75_CONTAM5_taxonomy_shorter.csv",header=T,row.names=1,check.names=FALSE)
meta_table<-read.csv("../../Data/metadata_binning.csv",header=T,row.names=1)
metabolites_table<-read.csv("../Metabolomics/Both_merged_PQN_BGI_IDonly.csv",header=T,row.names=1,check.names=FALSE)
rownames(metabolites_table) <- c("MP01", "MP02", "MP03", "MP04", "MP05",
"MP06", "MP07", "MP08",  "MP09",  "MP10",
"MP11", "MP12", "MP13", "MP14", "MP15",
"MP16", "MP17","MP18","MP19","MP20")
#/PARAMETERS ###########################
#Consolidate both abund_table and metabolites_table in the first instance
abund_table<-abund_table[rownames(abund_table) %in% rownames(metabolites_table),,drop=FALSE]
#Now shorten the meta_table
meta_table<-meta_table[rownames(abund_table),,drop=FALSE]
#Get rid of 0 count data from abund_table
abund_table<-abund_table[,colSums(abund_table)>0,drop=FALSE]
#At this point we have abund_table, meta_table, and metabolites_table are ready and their dimensions should match
#/DATA IMPORT############################################################
#PARAMETERS CHANGE THE GROUPING COLUMN AS YOU DESIRE############################
#In the hypothesis space, all you need is to select the rows in meta_table you are interested in
#and then allocate a column to meta_table$Groups that you want to use.
#Hypothesis 1:
label="Hypothesis1"
meta_table<-meta_table[meta_table$Group %in% c("T1","T2"),]
meta_table$Groups<-factor(as.character(meta_table$Group),levels=c(
"T1",
"T2"
))
#PARAMETERS CHANGE THE GROUPING COLUMN AS YOU DESIRE############################
#Adjust abund_table to contain only those rows that got selected in the Hypothesis space
abund_table<-abund_table[rownames(meta_table),,drop=FALSE]
#After adjustment, get rid of OTUs that are all empty
abund_table<-abund_table[,colSums(abund_table)>0]
#Adjust metabolites_table
metabolites_table<-metabolites_table[rownames(meta_table),,drop=FALSE]
#/COLLATE OTUS AT A PARTICULAR LEVEL#######################################
# function to perform pre-filtering
# http://mixomics.org/mixmc/pre-processing/
low.count.removal = function(
data, # OTU count data frame of size n (sample) x p (OTU)
percent=0.01 # cutoff chosen
){
keep.otu = which(colSums(data)*100/(sum(colSums(data))) > percent)
data.filter = data[,keep.otu]
return(list(data.filter = data.filter, keep.otu = keep.otu))
}
result.filter = low.count.removal(abund_table, percent=0.01)
abund_table = result.filter$data.filter
#INPUT to DIABLO: several abundance tables (abund_table,HBIs_table etc) and meta_table (with Groups already assigned)
#=============Umer's fancy normalisation function ===============#
fancy_normalisation<-function(abund_table,normalisation_method="none"){
#===Normalisation methods for count data===#
#TSS+ILR: Total Sum Scaling normalisation (TSS) followed by Isometric Log Ratio (ILR)
#TSS+CLR: Total Sum Scaling normalisation (TSS) followed by Centered Log Ratio (ILR)
#CSS: an extension of the quantile normalisation approach and consists of cumulative sum up to a percentile determined using a data-driven approach
#log-relative: Log relative normalisation
#RLE: Relative Log Expression
#TMM: Weighted Trimmed Mean of M-Values
#TMM50: TMM50 Normalisation
#median:  Median Normalisation
#upperquartile: Upper Quartile Normalisation
#varstab: Variance Stabilising Normalisation
#===Normalisation methods for meta data including flowcytometry and metabolomics===#
#autoscaling: useful for environmental data
#arcsinh: useful for flowcytometry data
#paretoscaling: useful for metabolomics data
#naive-log2: useful for everything else
#mean-centering: subtraction of variable averages from the data
#none: No normalisation
require(mixOmics)
# require(edgeR)
# require(DESeq)
# require(metagenomeSeq)
# require(RFmarkerDetector)
#The following links were used to get all these normalisation code
#Reference: https://cgrlucb.wikispaces.com/Normalization+and+Differential+Expression+with+edgeR+-+Kelly+Street
#Reference: http://dx.doi.org/10.4161/cib.25849
#Reference: http://www.ploscompbiol.org/article/info%3Adoi%2F10.1371%2Fjournal.pcbi.1003531
#Reference: http://mixomics.org/mixmc/pre-processing/
#Reference: https://github.com/dgrapov/TeachingDemos/wiki/Principal-Components-Analysis
if(normalisation_method %in% c("RLE","TMM","TMM50","median","upperquartile")){
counts<-t(as.matrix(abund_table))+1
cds<-NULL
if(normalisation_method=="RLE"){
cds<-calcNormFactors(DGEList(counts=counts,remove.zeros=TRUE),method="RLE")
} else if (normalisation_method=="TMM"){
cds<-calcNormFactors(DGEList(counts=counts,remove.zeros=TRUE),method="TMM")
} else if (normalisation_method=="TMM50"){
cds<-calcNormFactors(DGEList(counts=counts,remove.zeros=TRUE),method="TMM50",logratioTrim=0.49)
} else if (normalisation_method=="median"){
cds<-calcNormFactors(DGEList(counts=counts,remove.zeros=TRUE),method="upperquartile",p=0.5)
} else if (normalisation_method=="upperquartile"){
cds<-calcNormFactors(DGEList(counts=counts,remove.zeros=TRUE),method="upperquartile",p=0.75)
}
scale<-cds$samples$lib.size*cds$samples$norm.factors
normCounts <- round(t(t(counts)/scale)*mean(scale))
abund_table<-t(normCounts)
} else if(normalisation_method=="log-relative"){
abund_table<-log((abund_table+1)/(rowSums(abund_table)+dim(abund_table)[2]))
} else if(normalisation_method=="varstab"){
#From Susan Holme's paper
counts<-t(as.matrix(abund_table))+1
cds = newCountDataSet(counts, rep("A",dim(counts)[2]))
# First estimate library size factors
cds = estimateSizeFactors(cds)
# Variance estimation
cds = estimateDispersions(cds, method="blind", sharingMode="maximum", fitType="local")
# Determine which column(s) have the dispersion estimates
dispcol = grep("disp\\_", colnames(fData(cds)))
# Enforce that there are no infinite values in the dispersion estimates
if( any(!is.finite(fData(cds)[, dispcol])) ){
fData(cds)[which(!is.finite(fData(cds)[, dispcol])), dispcol] <- 0.0
}
vsmat = exprs(varianceStabilizingTransformation(cds))
abund_table<-t(vsmat)
} else if(normalisation_method=="CSS"){
#From mixOmics website
data.metagenomeSeq = newMRexperiment(t(abund_table),
featureData=NULL, libSize=NULL, normFactors=NULL) #using filtered data
p = cumNormStat(data.metagenomeSeq) #default is 0.5
data.cumnorm = cumNorm(data.metagenomeSeq, p=p)
#data.cumnorm
abund_table = t(MRcounts(data.cumnorm, norm=TRUE, log=TRUE))
} else if(normalisation_method %in% c("TSS+ILR","TSS+CLR")){
TSS.divide = function(x){
x/sum(x)
}
if(normalisation_method=="TSS+ILR"){
abund_table<-logratio.transfo(t(apply(abund_table+1, 1, TSS.divide)),logratio="ILR")
} else if (normalisation_method=="TSS+CLR"){
abund_table<-logratio.transfo(t(apply(abund_table+1, 1, TSS.divide)),logratio="CLR")
}
} else if(normalisation_method=="autoscaling"){
abund_table<-as.data.frame(scale(abund_table,center=T,scale=T))
} else if (normalisation_method=="naive-log2"){
abund_table<-log2(abund_table+1e-20)
} else if (normalisation_method=="arcsinh"){
#Apply arcsinh transformation (see Amir et al. 2013, Online Methods, "Processing of mass cytometry data")
Asinh_Scale <- 5
abund_table <- asinh(abund_table / Asinh_Scale)
} else if (normalisation_method=="mean-centering"){
#Reference:http://www.gastonsanchez.com/visually-enforced/how-to/2014/01/15/Center-data-in-R/
# center with 'colMeans()'
center_colmeans <- function(x) {
xcenter = colMeans(x)
x - rep(xcenter, rep.int(nrow(x), ncol(x)))
}
abund_table<-center_colmeans(abund_table)
} else if (normalisation_method=="paretoscaling"){
abund_table<-paretoscale(abund_table,exclude=T)
}
abund_table
}
#=============/Umer's fancy normalisation function ===============#
#PARAMETERS ###########################
#For DIABLO to work, we need combined "data", and a "design" matrix,
#you can put in as many abundance tables as you want, just make sure
#you choose an appripriate normalisation measure
normalisation_method_abund_table="TSS+CLR"
abund_table<-fancy_normalisation(abund_table,normalisation_method_abund_table)
mapping_table<-data.frame(row.names=colnames(abund_table),names=paste0("G",seq(1:ncol(abund_table))))
colnames(abund_table)<-mapping_table[colnames(abund_table),"names"]
View(abund_df)
fancy_normalisation<-function(abund_table,normalisation_method="none"){
#===Normalisation methods for count data===#
#TSS+ILR: Total Sum Scaling normalisation (TSS) followed by Isometric Log Ratio (ILR)
#TSS+CLR: Total Sum Scaling normalisation (TSS) followed by Centered Log Ratio (ILR)
#CSS: an extension of the quantile normalisation approach and consists of cumulative sum up to a percentile determined using a data-driven approach
#log-relative: Log relative normalisation
#RLE: Relative Log Expression
#TMM: Weighted Trimmed Mean of M-Values
#TMM50: TMM50 Normalisation
#median:  Median Normalisation
#upperquartile: Upper Quartile Normalisation
#varstab: Variance Stabilising Normalisation
#===Normalisation methods for meta data including flowcytometry and metabolomics===#
#autoscaling: useful for environmental data
#arcsinh: useful for flowcytometry data
#paretoscaling: useful for metabolomics data
#naive-log2: useful for everything else
#mean-centering: subtraction of variable averages from the data
#none: No normalisation
require(mixOmics)
# require(edgeR)
# require(DESeq)
# require(metagenomeSeq)
# require(RFmarkerDetector)
#The following links were used to get all these normalisation code
#Reference: https://cgrlucb.wikispaces.com/Normalization+and+Differential+Expression+with+edgeR+-+Kelly+Street
#Reference: http://dx.doi.org/10.4161/cib.25849
#Reference: http://www.ploscompbiol.org/article/info%3Adoi%2F10.1371%2Fjournal.pcbi.1003531
#Reference: http://mixomics.org/mixmc/pre-processing/
#Reference: https://github.com/dgrapov/TeachingDemos/wiki/Principal-Components-Analysis
if(normalisation_method %in% c("RLE","TMM","TMM50","median","upperquartile")){
counts<-t(as.matrix(abund_table))+1
cds<-NULL
if(normalisation_method=="RLE"){
cds<-calcNormFactors(DGEList(counts=counts,remove.zeros=TRUE),method="RLE")
} else if (normalisation_method=="TMM"){
cds<-calcNormFactors(DGEList(counts=counts,remove.zeros=TRUE),method="TMM")
} else if (normalisation_method=="TMM50"){
cds<-calcNormFactors(DGEList(counts=counts,remove.zeros=TRUE),method="TMM50",logratioTrim=0.49)
} else if (normalisation_method=="median"){
cds<-calcNormFactors(DGEList(counts=counts,remove.zeros=TRUE),method="upperquartile",p=0.5)
} else if (normalisation_method=="upperquartile"){
cds<-calcNormFactors(DGEList(counts=counts,remove.zeros=TRUE),method="upperquartile",p=0.75)
}
scale<-cds$samples$lib.size*cds$samples$norm.factors
normCounts <- round(t(t(counts)/scale)*mean(scale))
abund_table<-t(normCounts)
} else if(normalisation_method=="log-relative"){
abund_table<-log((abund_table+1)/(rowSums(abund_table)+dim(abund_table)[2]))
} else if(normalisation_method=="varstab"){
#From Susan Holme's paper
counts<-t(as.matrix(abund_table))+1
cds = newCountDataSet(counts, rep("A",dim(counts)[2]))
# First estimate library size factors
cds = estimateSizeFactors(cds)
# Variance estimation
cds = estimateDispersions(cds, method="blind", sharingMode="maximum", fitType="local")
# Determine which column(s) have the dispersion estimates
dispcol = grep("disp\\_", colnames(fData(cds)))
# Enforce that there are no infinite values in the dispersion estimates
if( any(!is.finite(fData(cds)[, dispcol])) ){
fData(cds)[which(!is.finite(fData(cds)[, dispcol])), dispcol] <- 0.0
}
vsmat = exprs(varianceStabilizingTransformation(cds))
abund_table<-t(vsmat)
} else if(normalisation_method=="CSS"){
#From mixOmics website
data.metagenomeSeq = newMRexperiment(t(abund_table),
featureData=NULL, libSize=NULL, normFactors=NULL) #using filtered data
p = cumNormStat(data.metagenomeSeq) #default is 0.5
data.cumnorm = cumNorm(data.metagenomeSeq, p=p)
#data.cumnorm
abund_table = t(MRcounts(data.cumnorm, norm=TRUE, log=TRUE))
} else if(normalisation_method %in% c("TSS+ILR","TSS+CLR")){
TSS.divide = function(x){
x/sum(x)
}
if(normalisation_method=="TSS+ILR"){
abund_table<-logratio.transfo(t(apply(abund_table+1, 1, TSS.divide)),logratio="ILR")
} else if (normalisation_method=="TSS+CLR"){
abund_table<-logratio.transfo(t(apply(abund_table+1, 1, TSS.divide)),logratio="CLR")
}
} else if(normalisation_method=="autoscaling"){
abund_table<-as.data.frame(scale(abund_table,center=T,scale=T))
} else if (normalisation_method=="naive-log2"){
abund_table<-log2(abund_table+1e-20)
} else if (normalisation_method=="arcsinh"){
#Apply arcsinh transformation (see Amir et al. 2013, Online Methods, "Processing of mass cytometry data")
Asinh_Scale <- 5
abund_table <- asinh(abund_table / Asinh_Scale)
} else if (normalisation_method=="mean-centering"){
#Reference:http://www.gastonsanchez.com/visually-enforced/how-to/2014/01/15/Center-data-in-R/
# center with 'colMeans()'
center_colmeans <- function(x) {
xcenter = colMeans(x)
x - rep(xcenter, rep.int(nrow(x), ncol(x)))
}
abund_table<-center_colmeans(abund_table)
} else if (normalisation_method=="paretoscaling"){
abund_table<-paretoscale(abund_table,exclude=T)
}
abund_table
}
normalisation_method_abund_table="TSS+CLR"
abund_table<-fancy_normalisation(abund_table,normalisation_method_abund_table)
#ACHTUNG: From the RStudio menu, click on "Session" and then "Set Working Directory" to "To Source File Location"
#Script for Data Integration Analysis for Biomarker Discovery using latent variable approaches for 'Omic studies (DIABLO)
abund_table
write.csv(abund_table,"abund_df.csv")
write.csv(abund_table,"abund_df.csv")
setwd("~/Dropbox/Gladys_Pangga_PhD/Analysis/DIABLO")
setwd("~/Desktop/Others/Portfolio/integrative_omics/analysis")
#ACHTUNG: From the RStudio menu, click on "Session" and then "Set Working Directory" to "To Source File Location"
#Script for Data Integration Analysis for Biomarker Discovery using latent variable approaches for 'Omic studies (DIABLO)
library(vegan)
library(ggplot2)
library(ape)
library(phangorn)
library(stringr)
library(reshape2)
library(mixOmics)
#PARAMETERS ###########################
abund_df<-read.csv("../data/taxonomy_abundance_normalised.csv",header=TRUE,row.names=1)
met_df<-read.csv("../data/metabolite_abundance.csv",header=T,row.names=1,check.names=FALSE)
met_df[met_df$Treatment=="No","Treatment"] <- "T1"
met_df[met_df$Treatment=="Yes","Treatment"] <- "T2"
met_df$Treatment <- as.factor(met_df$Treatment)
rownames(met_df) <- c("MP01", "MP02", "MP03", "MP04", "MP05",
"MP06", "MP07", "MP08",  "MP09",  "MP10",
"MP11", "MP12", "MP13", "MP14", "MP15",
"MP16", "MP17","MP18","MP19","MP20")
abund_df<-abund_df[,colSums(abund_df)>0]
#ACHTUNG: From the RStudio menu, click on "Session" and then "Set Working Directory" to "To Source File Location"
#Script for Data Integration Analysis for Biomarker Discovery using latent variable approaches for 'Omic studies (DIABLO)
library(vegan)
library(ggplot2)
library(ape)
library(phangorn)
library(stringr)
library(reshape2)
library(mixOmics)
#PARAMETERS ###########################
abund_df<-read.csv("../data/taxonomy_abundance_normalised.csv",header=TRUE,row.names=1)
met_df<-read.csv("../data/metabolite_abundance.csv",header=T,row.names=1,check.names=FALSE)
met_df[met_df$Treatment=="No","Treatment"] <- "T1"
met_df[met_df$Treatment=="Yes","Treatment"] <- "T2"
met_df$Treatment <- as.factor(met_df$Treatment)
rownames(met_df) <- c("MP01", "MP02", "MP03", "MP04", "MP05",
"MP06", "MP07", "MP08",  "MP09",  "MP10",
"MP11", "MP12", "MP13", "MP14", "MP15",
"MP16", "MP17","MP18","MP19","MP20")
mapping_table<-data.frame(row.names=colnames(abund_df),names=paste0("G",seq(1:ncol(abund_df))))
colnames(abund_df)<-mapping_table[colnames(abund_df),"names"]
View(abund_df)
#ACHTUNG: From the RStudio menu, click on "Session" and then "Set Working Directory" to "To Source File Location"
#Script for Data Integration Analysis for Biomarker Discovery using latent variable approaches for 'Omic studies (DIABLO)
library(vegan)
library(ggplot2)
library(ape)
library(phangorn)
library(stringr)
library(reshape2)
library(mixOmics)
#PARAMETERS ###########################
abund_df<-read.csv("../data/taxonomy_abundance_normalised.csv",header=TRUE,row.names=1)
met_df<-read.csv("../data/metabolite_abundance.csv",header=T,row.names=1,check.names=FALSE)
met_df[met_df$Treatment=="No","Treatment"] <- "T1"
met_df[met_df$Treatment=="Yes","Treatment"] <- "T2"
met_df$Treatment <- as.factor(met_df$Treatment)
rownames(met_df) <- c("MP01", "MP02", "MP03", "MP04", "MP05",
"MP06", "MP07", "MP08",  "MP09",  "MP10",
"MP11", "MP12", "MP13", "MP14", "MP15",
"MP16", "MP17","MP18","MP19","MP20")
data=list(metagenome=abund_df,metabolome=met_df)
design=matrix(0.1,ncol=length(data),nrow=length(data),dimnames=list(names(data),names(data)))
design
length(data)
names(data)
design=matrix(0.1,ncol=2,nrow=2,dimnames=c("metagenome","metabolome","metagenome","metabolome"))
#Now make a design matrix where all blocks (datasets) are connected with a link of 0.1
design=matrix(0.1,ncol=2,nrow=2,dimnames=list(c("metagenome","metabolome","metagenome","metabolome")))
#For DIABLO, we need to combine our data
data=list(metagenome=abund_df,metabolome=met_df)
#Now make a design matrix where all blocks (datasets) are connected with a link of 0.1
design=matrix(0.1,ncol=2,nrow=2,dimnames=list(names(data),names(data)))
data.diablo=block.splsda(X=data,Y=met_df$Treatment,ncomp=10,design=design)
View(data)
data=list(metagenome=abund_df,metabolome=met_df)
View(data)
#For DIABLO, we need to combine our data
data=list(metagenome=abund_df,metabolome=met_df[-1])
View(data)
data[["metagenome"]]
#ACHTUNG: From the RStudio menu, click on "Session" and then "Set Working Directory" to "To Source File Location"
#Script for Data Integration Analysis for Biomarker Discovery using latent variable approaches for 'Omic studies (DIABLO)
library(vegan)
library(ggplot2)
library(ape)
library(phangorn)
library(stringr)
library(reshape2)
library(mixOmics)
#PARAMETERS ###########################
abund_df<-read.csv("../data/taxonomy_abundance_normalised.csv",header=TRUE,row.names=1)
met_df<-read.csv("../data/metabolite_abundance.csv",header=T,row.names=1,check.names=FALSE)
met_df[met_df$Treatment=="No","Treatment"] <- "T1"
met_df[met_df$Treatment=="Yes","Treatment"] <- "T2"
met_df$Treatment <- as.factor(met_df$Treatment)
rownames(met_df) <- c("MP01", "MP02", "MP03", "MP04", "MP05",
"MP06", "MP07", "MP08",  "MP09",  "MP10",
"MP11", "MP12", "MP13", "MP14", "MP15",
"MP16", "MP17","MP18","MP19","MP20")
#For DIABLO, we need to combine our data
data=list(metagenome=abund_df,metabolome=met_df[-1])
#Now make a design matrix where all blocks (datasets) are connected with a link of 0.1
design=matrix(0.1,ncol=2,nrow=2,dimnames=list(names(data),names(data)))
data.diablo=block.splsda(X=data,Y=met_df$Treatment,ncomp=10,design=design)
data.diablo.perf<-perf(data.diablo,validation=cross_validation_type,folds=cross_validation_folds,progressBar=TRUE,auc=TRUE,nrepeat=cross_validation_repeats)
data.diablo=block.splsda(X=data,Y=met_df$Treatment,ncomp=10,design=design)
data.diablo.perf<-perf(data.diablo,validation=cross_validation_type,folds="loo",progressBar=TRUE,auc=TRUE,nrepeat=10)
#Step 1:
data.diablo=block.splsda(X=data,Y=met_df$Treatment,ncomp=10,design=design)
data.diablo.perf<-perf(data.diablo,validation="loo",folds=5,progressBar=TRUE,auc=TRUE,nrepeat=10)
#Step 1:
data.diablo=block.splsda(X=data,Y=met_df$Treatment,ncomp=10,design=design)
data.diablo.perf<-perf(data.diablo,validation="loo",folds=5,progressBar=TRUE,auc=TRUE,nrepeat=10)
pdf(paste("Step.1-DIABLO_performance_",label,".pdf",sep=""), height=4,width=10)
plot(data.diablo.perf, overlay = 'measure', sd = TRUE)
dev.off()
ncomp=2
if(manual_tunning){
ncomp=tuning_components
} else {
ncomp=data.diablo.perf$choice.ncomp$WeightedVote["Overall.BER",distance_matrix]
}
ncomp=2
if(manual_tunning){
ncomp=tuning_components
} else {
ncomp=data.diablo.perf$choice.ncomp$WeightedVote["Overall.BER",distance_matrix]
}
data.diablo.tune=tune.block.splsda(X=data,
Y=met_df$Treatment,
ncomp=2,
design=design,
test.keepX=list(metagenome=c(seq(10,50,5)),metabolome=c(seq(50,500,50))),
validation="loo",
folds=5,
measure="overall",
nrepeat=10,
dist="centroids.dist")
list.keepX=data.diablo.tune$choice.keepX
